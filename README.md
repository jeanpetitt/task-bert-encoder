# Implementation of differents tasks of the encoder using bert

in this project we are using Bert and DistillBert to implement all tasks that an encoder can make.

the different task which encoder can do are:

- text encoding: in this task bert take as inputs a word sequence or character and tranform it in a vector representation view it on
[text_encoding](/text_encoding/test.py)

- Representation Learning: we used bert to help us to represent the text in such a way as to capture the relationships between words, phrases and documents. to build it we used technics like Deep learning, NLP to extract these information. view more in [representation learning](/representation_learning/test.py)

- caracteristiques extraction: bert can extract specifiques feature of the text, like entity, sentiments, topics and others infos. view more on [extract caracteristique](/features_extraction/test.py)

- text génération: bert are used to generate text from a vector representation.
view more on [text generation](/text_generation/test.py)
